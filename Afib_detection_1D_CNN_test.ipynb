{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import io\n",
    "from collections import Counter\n",
    "Fs_data=400\n",
    "Fs=50\n",
    "ob_time=30\n",
    "stride_time=10\n",
    "data_idx=1\n",
    "CART_add=False\n",
    "test_mode=0 # 0: physiolab, 1: CART data\n",
    "num_models = 7\n",
    "flip_mod=True\n",
    "if test_mode==0:\n",
    "    if flip_mod==True:\n",
    "        f='data_set_idx({0})_stride({1})_obtime_{2}s_filp.npz'.format(data_idx, stride_time,ob_time)\n",
    "    else:\n",
    "        f='data_set_idx({0})_stride({1})_obtime_{2}s.npz'.format(data_idx, stride_time,ob_time)\n",
    "    data_load=np.load(f)\n",
    "    test_set=data_load['c']\n",
    "    test_label=data_load['d']\n",
    "    N_test=len(test_set)\n",
    "elif test_mode==1:\n",
    "    mat_file = io.loadmat('ECG_denoising.mat')\n",
    "    data_set=mat_file['ECG_buf']\n",
    "    if CART_add == True:\n",
    "        N_train_CART=100\n",
    "        for idx in range(N_train_CART,204):\n",
    "            tmp_set=np.zeros((1,Fs*ob_time))\n",
    "            L=data_set.shape\n",
    "            tmp=data_set[idx]    \n",
    "            tmp_set[0]=tmp[0:L[1]:int(Fs_data/Fs)]\n",
    "            tmp_set=tmp_set-np.min(tmp_set)\n",
    "            tmp_set=tmp_set/np.max(tmp_set)\n",
    "            if idx==N_train_CART:\n",
    "                test_set=tmp_set\n",
    "            else:\n",
    "                test_set=np.append(test_set,tmp_set,axis=0)\n",
    "            N_test=L[0]-N_train_CART\n",
    "        test_label=np.zeros((N_test,2))\n",
    "        test_label[:]=[0,1]\n",
    "    elif CART_add==False:\n",
    "        for idx in range(0,204):\n",
    "            tmp_set=np.zeros((1,Fs*ob_time))\n",
    "            L=data_set.shape\n",
    "            tmp=data_set[idx]    \n",
    "            tmp_set[0]=tmp[0:L[1]:int(Fs_data/Fs)]\n",
    "            tmp_set=tmp_set-np.min(tmp_set)\n",
    "            tmp_set=tmp_set/np.max(tmp_set)\n",
    "            if idx==0:\n",
    "                test_set=tmp_set\n",
    "            else:\n",
    "                test_set=np.append(test_set,tmp_set,axis=0)\n",
    "            N_test=len(test_set)\n",
    "        test_label=np.zeros((N_test,2))\n",
    "        test_label[:]=[0,1]\n",
    "test_set=test_set.reshape(N_test,1,Fs*ob_time,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_unit=128\n",
    "L2_unit=256\n",
    "L3_unit=512\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X = tf.placeholder(tf.float32,shape=[None,1,Fs*ob_time,1])\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None,2])\n",
    "            self.keep_prob1 = self.keep_prob2 = self.keep_prob3 = tf.placeholder(tf.float32)\n",
    "            W1 = tf.Variable(tf.random_normal([1,9,1,L1_unit], stddev = 0.01))\n",
    "            L1 = tf.nn.conv2d(self.X, W1, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.dropout(self.L1, self.keep_prob1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            ###(1,750)\n",
    "            W2 = tf.Variable(tf.random_normal([1,9,L1_unit,L2_unit], stddev = 0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.dropout(self.L2, self.keep_prob2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            #######(1,375)\n",
    "            W3 = tf.Variable(tf.random_normal([1,9,L2_unit,L3_unit], stddev = 0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.dropout(self.L3, self.keep_prob3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            \n",
    "            Wf = tf.Variable(tf.random_normal([1*int(Fs*ob_time/64+1)*L3_unit,2], stddev = 0.01))\n",
    "            L = tf.reshape(L3,[-1,1*int(Fs*ob_time/64+1)*L3_unit])\n",
    "            self.model = tf.matmul(L,Wf)\n",
    "        x=tf.argmax(self.model, 1)\n",
    "        y=tf.argmax(self.Y, 1)\n",
    "        is_correct = tf.equal(x, y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    def predict(self, x_test,y_test, keep_prop1=1.0,keep_prop2=1.0,keep_prop3=1.0):\n",
    "        return self.sess.run([self.accuracy,self.model], feed_dict={self.X: x_test,\n",
    "                                                                    self.Y: y_test,\n",
    "                                                                    self.keep_prob1: keep_prop1,\n",
    "                                                                    self.keep_prob2: keep_prop2,\n",
    "                                                                    self.keep_prob3: keep_prop3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ce54e5de34c7>:19: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model/1D_CNN_model_dataset(1)_CART_False_model(7)_stride(10)_obtime(30)_normalization_x.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess =tf.Session()\n",
    "models = []\n",
    "\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "if data_idx==5:\n",
    "    save_file = './model/1D_CNN_model_dataset(all)_CART_{0}_model({1})_flip_{2}.ckpt' .format(CART_add,num_models,flip_mod)\n",
    "else:\n",
    "    save_file = './model/1D_CNN_model_dataset({0})_CART_{1}_model({2})_stride({3})_obtime({4})_flip_{5}.ckpt' .format(data_idx,CART_add,num_models,stride_time,ob_time,flip_mod)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, save_file)\n",
    "\n",
    "test_batch=100\n",
    "test_len=len(test_set)\n",
    "total_batch=int(np.ceil(test_len/test_batch))\n",
    "predictions = np.zeros([test_len, 2])\n",
    "each_predictions = np.zeros([num_models,test_len, 2])\n",
    "for i in range(total_batch):\n",
    "    batch_x = test_set[i*test_batch:(i+1)*test_batch]\n",
    "    batch_y = test_label[i*test_batch:(i+1)*test_batch]\n",
    "    for m_idx, m in enumerate(models):\n",
    "        a,p = m.predict(batch_x,batch_y)\n",
    "        predictions[i*test_batch:(i+1)*test_batch] += p[:]\n",
    "        each_predictions[m_idx][i*test_batch:(i+1)*test_batch][:]=p[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network  1\n",
      "Acc. :  0.6817215727948991\n",
      "sensitivity :  0.6931818181818181\n",
      "specificity :  0.6695842450765864\n",
      " \n",
      "network  2\n",
      "Acc. :  0.7532766560396741\n",
      "sensitivity :  0.5988292011019284\n",
      "specificity :  0.9168490153172867\n",
      " \n",
      "network  3\n",
      "Acc. :  0.7208643287283032\n",
      "sensitivity :  0.5692148760330579\n",
      "specificity :  0.8814733770970095\n",
      " \n",
      "network  4\n",
      "Acc. :  0.7493800921006022\n",
      "sensitivity :  0.59400826446281\n",
      "specificity :  0.9139314369073669\n",
      " \n",
      "network  5\n",
      "Acc. :  0.7546935883811547\n",
      "sensitivity :  0.5953856749311295\n",
      "specificity :  0.9234135667396062\n",
      " \n",
      "network  6\n",
      "Acc. :  0.7215727948990436\n",
      "sensitivity :  0.5568181818181819\n",
      "specificity :  0.8960612691466083\n",
      " \n",
      "network  7\n",
      "Acc. :  0.7217499114417286\n",
      "sensitivity :  0.5778236914600551\n",
      "specificity :  0.8741794310722101\n",
      " \n",
      "ensemble method\n",
      "Acc. :  0.7401700318809776\n",
      "sensitivity :  0.5764462809917356\n",
      "specificity :  0.9135667396061269\n"
     ]
    }
   ],
   "source": [
    "if test_mode==0:\n",
    "    for idx in range(num_models):\n",
    "        buf=np.argmax(test_label,axis=1)-np.argmax(each_predictions[idx],axis=1)\n",
    "        buf_label=np.argmax(test_label,axis=1)\n",
    "        count1 = Counter(buf)\n",
    "        count2 = Counter(buf_label)\n",
    "        label_AF_pred_SR=count1[-1]/count2[0] \n",
    "        label_SR_pred_AF=count1[1]/count2[1] \n",
    "        print('network ',(idx+1))\n",
    "        print('Acc. : ',count1[0]/test_len)         \n",
    "        print('sensitivity : ',1-label_AF_pred_SR) \n",
    "        print('specificity : ',1-label_SR_pred_AF)  \n",
    "        print(' ')\n",
    "    if num_models!=1:\n",
    "        buf=np.argmax(test_label,axis=1)-np.argmax(predictions,axis=1)\n",
    "        buf_label=np.argmax(test_label,axis=1)\n",
    "        count1 = Counter(buf)\n",
    "        count2 = Counter(buf_label)\n",
    "        label_AF_pred_SR=count1[-1]/count2[0] \n",
    "        label_SR_pred_AF=count1[1]/count2[1]    \n",
    "        print('ensemble method')\n",
    "        print('Acc. : ',count1[0]/test_len)         \n",
    "        print('sensitivity : ',1-label_AF_pred_SR) \n",
    "        print('specificity : ',1-label_SR_pred_AF)\n",
    "elif test_mode==1:\n",
    "    for idx in range(num_models):\n",
    "        buf=np.argmax(test_label,axis=1)-np.argmax(each_predictions[idx],axis=1)\n",
    "        buf_label=np.argmax(test_label,axis=1)\n",
    "        count1 = Counter(buf)\n",
    "        count2 = Counter(buf_label)\n",
    "        label_SR_pred_AF=count1[1]/count2[1] \n",
    "        print('network ',(idx+1))\n",
    "        print('Acc. : ',count1[0]/test_len)          \n",
    "        print('specificity : ',1-label_SR_pred_AF)  \n",
    "        print(' ')\n",
    "    if num_models!=1:\n",
    "        buf=np.argmax(test_label,axis=1)-np.argmax(predictions,axis=1)\n",
    "        buf_label=np.argmax(test_label,axis=1)\n",
    "        count1 = Counter(buf)\n",
    "        count2 = Counter(buf_label)\n",
    "        label_SR_pred_AF=count1[1]/count2[1]    \n",
    "        print('ensemble method')\n",
    "        print('Acc. : ',count1[0]/test_len)         \n",
    "        print('specificity : ',1-label_SR_pred_AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
