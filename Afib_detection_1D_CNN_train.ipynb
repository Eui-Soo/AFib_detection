{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import io\n",
    "\n",
    "\n",
    "Fs_data=400\n",
    "Fs=50\n",
    "ob_time=30\n",
    "stride_time=10\n",
    "data_idx=4\n",
    "CART_add=False\n",
    "num_models = 7\n",
    "flip_mod=True\n",
    "\n",
    "if data_idx==5:\n",
    "    if flip_mod==True:\n",
    "        f='data_set_all_stride({0})_flip.npz'.format(stride_time)\n",
    "    else:\n",
    "        f='data_set_all_stride({0}).npz'.format(stride_time)\n",
    "else:\n",
    "    f='data_set_idx({0})_stride({1})_obtime_{2}s.npz'.format(data_idx, stride_time,ob_time)\n",
    "data_load=np.load(f)\n",
    "train_set=data_load['a']\n",
    "train_label=data_load['b']\n",
    "if CART_add==True:    \n",
    "    mat_file = io.loadmat('ECG_denoising.mat')\n",
    "    data_set=mat_file['ECG_buf']\n",
    "    N_train_CART=100\n",
    "    N_rep=10\n",
    "    for nn in range(N_rep):\n",
    "        for idx in range(N_train_CART):\n",
    "            tmp_set=np.zeros((1,Fs*ob_time))\n",
    "            L=data_set.shape\n",
    "            tmp=data_set[idx]    \n",
    "            tmp_set[0]=tmp[0:L[1]:int(Fs_data/Fs)]\n",
    "            tmp_set=tmp_set-np.min(tmp_set)\n",
    "            tmp_set=tmp_set/np.max(tmp_set)\n",
    "            if idx==0 and nn==0:\n",
    "                train_set_CART=tmp_set\n",
    "            else:\n",
    "                train_set_CART=np.append(train_set_CART,tmp_set,axis=0)\n",
    "    if flip_mod==True:\n",
    "        train_tmp_set=train_set_CART\n",
    "        train_tmp_set=(train_tmp_set-1)*(-1)\n",
    "        train_set_CART=np.append(train_set_CART,train_tmp_set,axis=0)   \n",
    "        tmp_label=np.zeros((N_train_CART*N_rep*2,2))\n",
    "    else:\n",
    "        tmp_label=np.zeros((N_train_CART*N_rep,2))\n",
    "    tmp_label[:]=[0,1]\n",
    "    train_label=np.append(train_label,tmp_label,axis=0)\n",
    "    train_set=np.append(train_set,train_set_CART,axis=0)   \n",
    "N_train=len(train_set)\n",
    "shuffle_idx=np.random.permutation(N_train)\n",
    "train_set=train_set[shuffle_idx]\n",
    "train_label=train_label[shuffle_idx]\n",
    "train_set=train_set.reshape(N_train,1,Fs*ob_time,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_gen(S,Epoch,Total_Epoch):\n",
    "    seconds=time.time()-S\n",
    "    seconds=seconds*(Total_Epoch-Epoch-1)\n",
    "    hour=seconds//3600\n",
    "    minute=(seconds%3600)//60\n",
    "    second=(seconds%3600)%60\n",
    "    if hour > 0:\n",
    "        time_result=\"%d hour %d min %d sec\" % (hour,minute,second)\n",
    "    elif hour == 0 and minute>0:\n",
    "        time_result=\"%d min %d sec\" % (minute,second)\n",
    "    elif hour == 0 and minute==0:\n",
    "        time_result=\"%d sec\" % second\n",
    "    return time_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 200\n",
    "train_len=len(train_set)\n",
    "total_batch = int(train_len/batch_size)\n",
    "L1_unit=128\n",
    "L2_unit=256\n",
    "L3_unit=512\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X = tf.placeholder(tf.float32,shape=[None,1,Fs*ob_time,1])\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None,2])\n",
    "            self.keep_prob1 = self.keep_prob2 = self.keep_prob3 = tf.placeholder(tf.float32)\n",
    "            \n",
    "            W1 = tf.Variable(tf.random_normal([1,9,1,L1_unit], stddev = 0.01))\n",
    "            L1 = tf.nn.conv2d(self.X, W1, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.dropout(self.L1, self.keep_prob1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            \n",
    "            W2 = tf.Variable(tf.random_normal([1,9,L1_unit,L2_unit], stddev = 0.01))\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.dropout(self.L2, self.keep_prob2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            \n",
    "            W3 = tf.Variable(tf.random_normal([1,9,L2_unit,L3_unit], stddev = 0.01))\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding = 'SAME')\n",
    "            self.L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.dropout(self.L3, self.keep_prob3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "            \n",
    "            Wf = tf.Variable(tf.random_normal([1*int(Fs*ob_time/64+1)*L3_unit,2], stddev = 0.01))\n",
    "            L = tf.reshape(L3,[-1,1*int(Fs*ob_time/64+1)*L3_unit])\n",
    "            self.model = tf.matmul(L,Wf)\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.model, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.cost)\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop1=0.7,keep_prop2=0.8,keep_prop3=0.9):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data,\n",
    "            self.Y: y_data,\n",
    "            self.keep_prob1: keep_prop1,\n",
    "            self.keep_prob2: keep_prop2,\n",
    "            self.keep_prob3: keep_prop3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-ec4b02ff8c9d>:25: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = [0.31769264 0.31596056 0.3021509  0.3116822  0.3175321  0.33210257\n",
      " 0.29637923]\n",
      "Time remaining : 10 min 22 sec\n",
      "Epoch: 0002 cost = [0.04806728 0.0467767  0.04389373 0.04673602 0.0449038  0.04065832\n",
      " 0.03340193]\n",
      "Time remaining : 9 min 0 sec\n",
      "Epoch: 0003 cost = [0.05245309 0.03722365 0.02418717 0.05400435 0.09408873 0.05143809\n",
      " 0.06854099]\n",
      "Time remaining : 7 min 53 sec\n",
      "Epoch: 0004 cost = [0.05864898 0.02056797 0.05524816 0.01527488 0.01708722 0.01851986\n",
      " 0.01091832]\n",
      "Time remaining : 6 min 46 sec\n",
      "Epoch: 0005 cost = [0.00879597 0.00797638 0.01629523 0.01008628 0.00763757 0.0103633\n",
      " 0.00894108]\n",
      "Time remaining : 5 min 37 sec\n",
      "Epoch: 0006 cost = [0.00562674 0.00647659 0.00709465 0.00535817 0.00646025 0.00737312\n",
      " 0.00567652]\n",
      "Time remaining : 4 min 30 sec\n",
      "Epoch: 0007 cost = [0.00421245 0.00354339 0.00496022 0.0457702  0.08825345 0.0043931\n",
      " 0.00657739]\n",
      "Time remaining : 3 min 22 sec\n",
      "Epoch: 0008 cost = [0.00260539 0.44252689 0.01066622 0.0055107  0.01189755 0.00932846\n",
      " 0.00712397]\n",
      "Time remaining : 2 min 15 sec\n",
      "Epoch: 0009 cost = [0.01056224 0.13782736 0.00358563 0.00512752 0.00398242 0.00307932\n",
      " 0.00242817]\n",
      "Time remaining : 1 min 7 sec\n",
      "Epoch: 0010 cost = [0.0068695  0.05447958 0.00165089 0.00362768 0.00250397 0.01091545\n",
      " 0.00847928]\n",
      "Time remaining : 0 sec\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "sess =tf.Session()\n",
    "models = []\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "saver = tf.train.Saver()\n",
    "if data_idx==5:\n",
    "    save_file = './model/1D_CNN_model_dataset(all)_CART_{0}_model({1})_flip_{2}.ckpt' .format(CART_add,num_models,flip_mod)\n",
    "else:\n",
    "    save_file = './model/1D_CNN_model_dataset({0})_CART_{1}_model({2})_stride({3})_obtime({4})_flip_{5}.ckpt' .format(data_idx,CART_add,num_models,stride_time,ob_time,flip_mod)\n",
    "        \n",
    "for epoch in range(epochs):\n",
    "    S=time.time()\n",
    "    avg_cost = np.zeros(len(models))\n",
    "    for i in range(total_batch):\n",
    "        batch_x = train_set[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y = train_label[i*batch_size:(i+1)*batch_size]\n",
    "        for m_idx, m in enumerate(models):\n",
    "            cost_val,_ = m.train(batch_x, batch_y)\n",
    "            avg_cost[m_idx] += cost_val / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost)\n",
    "    print('Time remaining : '+ time_gen(S,epoch,epochs))\n",
    "saver.save(sess, save_file)\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
